# -*- coding: utf-8 -*-
"""Customer_churn_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ynNHDjcWY6gjoyb2QLe-FEy2JW0RGDe

Basic imports
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

"""Reading dataset"""

data=pd.read_csv('/content/drive/MyDrive/Dataset/Telco_Customer_Churn.csv')
data.head()

#shape of the dataset
data.shape

"""Droping the customerID column because it has no significant for predicting churn"""

data.drop('customerID',axis=1,inplace=True)

data.dtypes

"""TotalCharges is object type, so review the TotalCharges column"""

data.TotalCharges.values

"""We can see that it is string type so lets change it into numeric"""

pd.to_numeric(data.TotalCharges)

"""Some values seems like missing values"""

pd.to_numeric(data.TotalCharges,errors='coerce').isnull()

data[pd.to_numeric(data.TotalCharges,errors='coerce').isnull()]

data.shape

data.iloc[488]['TotalCharges']

"""creating a new dataset by remove the rows which has missing value of the TotalCharges"""

data_new=data[data.TotalCharges!=' ']

"""We can neglect the 11 rows over 7043 rows"""

data_new.shape

data_new.dtypes

data_new.TotalCharges=pd.to_numeric(data_new.TotalCharges)

data_new.TotalCharges.values

data_new[data_new.Churn=='No']

"""Visualizing tenure column"""

tenure_churn_no=data_new[data_new.Churn=='No'].tenure
tenure_churn_yes=data_new[data_new.Churn=='Yes'].tenure

plt.xlabel('Tenure')
plt.ylabel('Number of Customers')
plt.title('Customer Churn Prediction Visualisation')
plt.hist([tenure_churn_yes,tenure_churn_no], color=['green', 'red'], label=['Churn=Yes', 'Churn=No'])
plt.legend()

"""Visualizing MonthlyCharges column"""

mc_churn_no=data_new[data_new.Churn=='No'].MonthlyCharges
mc_churn_yes=data_new[data_new.Churn=='Yes'].MonthlyCharges

plt.xlabel('Monthly Charges')
plt.ylabel('Number of Customers')
plt.title('Customer Churn Prediction Visualisation')

blood_sugar_men = [113, 85, 90, 150, 149, 88, 93, 115, 135, 80, 77, 82, 120]
blood_sugar_women = [67, 98, 89, 120, 133, 150, 84, 69, 89, 79, 120, 112, 100]

plt.hist([mc_churn_yes,mc_churn_no], rwidth=0.95, color=['green', 'red'], label=['Churn=Yes', 'Churn=No'])
plt.legend()

"""many of the features are in yes and no values
priting the unique values
"""

def print_unique_col_values(data):
  for column in data_new:
    if data_new[column].dtypes=='object':
      print(f'{column} : {data_new[column].unique()}')

print_unique_col_values(data_new)

"""replace the "No internet service" and "No phone service" >> "No"
"""

data_new.replace('No internet service','No',inplace=True)
data_new.replace('No phone service','No',inplace=True)

print_unique_col_values(data_new)

"""converting yes and no >> 1 and 0"""

yes_no_columns=['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',
                'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']

for col in yes_no_columns:
  data_new[col].replace({'Yes':1,'No':0},inplace=True)

for col in data_new:
  print(f'{col} : {data_new[col].unique()}')

"""converting female and male >> 1 and 0"""

data_new['gender'].replace({'Female':1,'Male':0},inplace=True)

data_new['gender'].unique()

"""one hot encoding for the categorical columns"""

#one hot encoding
from sklearn.preprocessing import OneHotEncoder

onehotencoder = OneHotEncoder()
part = onehotencoder.fit_transform(data_new['InternetService'].values.reshape(-1,1)).toarray()

values = dict(data_new["InternetService"].value_counts())

for e , (val , _) in enumerate(values.items()):
    data_new["InternetService_" + str(val)] = part[:,e]

data_new = data_new.drop(["InternetService"] , axis = 1)

data_new.head()

part = onehotencoder.fit_transform(data_new['Contract'].values.reshape(-1,1)).toarray()

values = dict(data_new["Contract"].value_counts())

for e , (val , _) in enumerate(values.items()):
    data_new["Contract_" + str(val)] = part[:,e]

data_new = data_new.drop(["Contract"] , axis = 1)

data_new.head()

part = onehotencoder.fit_transform(data_new['PaymentMethod'].values.reshape(-1,1)).toarray()

values = dict(data_new["PaymentMethod"].value_counts())

for e , (val , _) in enumerate(values.items()):
    data_new["PaymentMethod_" + str(val)] = part[:,e]

data_new = data_new.drop(["PaymentMethod"] , axis = 1)

data_new.head()

data_new.dtypes

"""As we can see that all the dtypes in float and int
Now, we have to scale the tenure, MonthlyCharges and TotalCharges
"""

cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
data_new[cols_to_scale] = scaler.fit_transform(data_new[cols_to_scale])

data_new.sample(5)

for col in data_new:
  print(f'{col} : {data_new[col].unique()}')

"""Train and test split"""

X= data_new.drop('Churn',axis='columns')
y=data_new['Churn']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=5)

X_train.shape

X_test.shape

import tensorflow as tf
from tensorflow import keras

model=keras.Sequential([
    keras.layers.Dense(26,input_shape=(26,),activation='relu'),
    keras.layers.Dense(15,activation='relu'),
    keras.layers.Dense(1,activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.fit(X_train,y_train,epochs=100)

model.evaluate(X_test,y_test)

yp=model.predict(X_test)
yp[:10]

y_test[:10]

y_pred=[]
for element in yp:
  if element>0.5:
    y_pred.append(1)
  else:
    y_pred.append(0)

y_pred[:10]

from sklearn.metrics import confusion_matrix , classification_report

print(classification_report(y_test,y_pred))

import seaborn as sn
cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)

plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""Accuracy"""

round((855+241)/(855+144+167+241),2)

"""precision for 0 class, precision for customers who did not churn"""

round(855/(855+167),2)

"""precision for 1 class, precision for customers who actually churn"""

round(241/(241+144),2)

"""recall for 0 class"""

round(855/(855+144),2)

"""recall for 1 class"""

round(241/(241+167),2)